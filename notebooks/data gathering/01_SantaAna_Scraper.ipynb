{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Projects/regionintelligenceai/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major planning projects and monthly development reports - City of Santa Ana\n"
     ]
    }
   ],
   "source": [
    "# Import driver configuration\n",
    "import time\n",
    "import numpy as np\n",
    "from src.config.driver_config import get_chrome_driver, navigate_and_print_title, main\n",
    "\n",
    "driver = get_chrome_driver()\n",
    "\n",
    "URL = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "\n",
    "# Navigate to the URL and print its title\n",
    "navigate_and_print_title(driver, URL)\n",
    "\n",
    "# If you need to close the driver after use (recommended if not using further in the notebook):\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st and Harbor Mix-Use Development\n",
      "3rd and Broadway Mix-Use Development\n",
      "4th and Mortimer Mixed-Used Development\n",
      "5th and Harbor Mixed-Use Development\n",
      "7-Eleven Service Station (Euclid Street)\n",
      "AMG Senior Housing\n",
      "AMG First Point Family Affordable Apartments\n",
      "Bella Terra Residential Community and Temple\n",
      "Bewley Townhomes\n",
      "Billboard Ordinance\n",
      "Warner Redhill Mixed-Use Development (formerly the Bowery)\n",
      "Bristol Corridor Specific Plan Amendment\n",
      "Cabrillo Crossing Townhomes\n",
      "Cabrillo Town Center\n",
      "Calvary Church\n",
      "Central Pointe Mixed-Use Development\n",
      "Climate Action Plan\n",
      "Complete Streets Plans\n",
      "Community Engagement Plan\n",
      "Coptic Orthodox Church\n",
      "Crossroads at Washington\n",
      "First American Title Company Mixed-Use Development\n",
      "FX Residences\n",
      "Garry Avenues Business Park\n",
      "General Plan Update\n",
      "Grand and Grovemont Development\n",
      "Haphan Residential\n",
      "Harbor Boulevard Streetscape Plan\n",
      "The Heritage\n",
      "Illumination Foundation Renovation Project\n",
      "Innovative Housing Opportunities Mixed-Use Project\n",
      "Legacy Square\n",
      "Legacy Sunflower\n",
      "Legado at the Met\n",
      "The Madison\n",
      "MainPlace Mall Transformation Project\n",
      "McDonalds's Drive-Through Restaurant\n",
      "Metro East Mixed Use Overlay Zone Expansion\n",
      "Mountain View Residential Development\n",
      "One Broadway Plaza\n",
      "Park 55 Industrial Redevelopment Project\n",
      "Related California Bristol Specific Plan\n",
      "Russell Fischer Commercial\n",
      "South Coast Technology Center \n",
      "Standard/McFadden Park\n",
      "Lacy Crossing (Formerly Tom's Trucks Residential and Adaptive Use)\n",
      "The Village Specific Plan\n",
      "Vista Heritage Development Project\n",
      "Warmington Residential Development\n",
      "Washington Avenue Residential Development\n",
      "Elan (Formerly Wermers Elk Site Mixed-Use Development)\n",
      "The Westerly\n",
      "Westview Housing\n",
      "WISEPlace PSH Adaptive Reuse Development\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def extract_listing_names_from_url(driver, url):\n",
    "    \"\"\"\n",
    "    Navigates to a specified URL using the given driver and extracts listing names (or project names) from a table.\n",
    "    \n",
    "    Parameters:\n",
    "    - driver: Selenium WebDriver\n",
    "    - url: Webpage URL\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of extracted listing names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    listing_names = []\n",
    "    \n",
    "    # Wait for the table to be present and then locate it\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "    )\n",
    "    \n",
    "    # Extract the names from the first cell of each row\n",
    "    titles = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:first-of-type\")\n",
    "    for title in titles:\n",
    "        listing_names.append(title.text)\n",
    "\n",
    "    return listing_names\n",
    "\n",
    "# Example usage:\n",
    "driver = get_chrome_driver()\n",
    "URL = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "listing_names = extract_listing_names_from_url(driver, URL)\n",
    "for name in listing_names:\n",
    "    print(name)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 N. Harbor Boulevard (Ward 5)\n",
      "201 W. 3rd Street (Ward 5)\n",
      "409 E. 4th Street (Ward 6)\n",
      "419 N. Harbor Blvd (Ward 5)\n",
      "813 N. Euclid Street (Ward 1)\n",
      "2202 E. 1st Street (Ward 3)\n",
      "2114 E. 1st Street (Ward 3)\n",
      "4006 W. Hazard Avenue\n",
      "1122 N. Bewley Street (Ward 1)\n",
      "Citywide\n",
      "2300 S. Red Hill Avenue (Ward 6)\n",
      "N/A\n",
      "1814 E. First Street (Ward 3)\n",
      "1901 E. Fourth Street (Ward 3)\n",
      "1010 N. Tustin Avenue (Ward 3)\n",
      "1801 E. 4th Street (Ward 3)\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "4405 W. Edinger Avenue (Ward 1)\n",
      "1126 E. Washington Avenue (Ward 3)\n",
      "114 E. 5Th Street (Ward 6)\n",
      "801 E. Santa Ana Blvd. (Ward 6)\n",
      "1700 E. Garry Avenue (Ward 6)\n",
      "N/A\n",
      "2525 N. Grand Avenue (Ward 3)\n",
      "3025 W. Edinger Avenue (Ward 1)\n",
      "Harbor Boulevard\n",
      "2001 E. Dyer Road (Ward 6)\n",
      "918 N. Bewley Street   (Ward 5)\n",
      "2021 E. 4th Street (Ward 3)\n",
      "609 N. Spurgeon Street (Ward 6)\n",
      "651 W. Sunflower Avenue (Ward 6)\n",
      "200 E. First American Way (Ward 6)\n",
      "200 N. Cabrillo Park Drive (Ward 3)\n",
      "2800 N. Main Street (Ward 3)\n",
      "2101 E. Santa Clara Avenue  (Ward 3)\n",
      "N/A\n",
      "301 N. Mountain View Street (Ward 1)\n",
      "1109 N. Broadway (Ward 5)\n",
      "1221 E. Dyer Road (Ward 6)\n",
      "3600 S. Bristol St. (Ward 4)\n",
      "301 and 325 N. Tustin Avenue (Ward 3)\n",
      "3100, 3110, 3120 W. Lake Center Drive\n",
      "1117 S. Standard Avenue (Ward 6)\n",
      "1008 E. 4th Street (Ward 6)\n",
      "1561 W. Sunflower Avenue (Ward 4)\n",
      "601 N. Fairview Street (Ward 5)\n",
      "717 S. Lyon Street (Ward 3)\n",
      "1921 W. Washington Avenue (Ward 5)\n",
      "1660 E. 1st Street (Ward 3)\n",
      "2020 E. First Street (Ward 1)\n",
      "2534 W. Westminster Avenue (Ward 5)\n",
      "1411 N. Broadway (Ward 5)\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def extract_addresses_from_url(driver, url):\n",
    "    \"\"\"\n",
    "    Navigates to a specified URL using the given driver and extracts addresses from a table.\n",
    "    \n",
    "    Parameters:\n",
    "    - driver: Selenium WebDriver\n",
    "    - url: Webpage URL\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of extracted addresses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    project_locations = []\n",
    "    \n",
    "    # Wait for the table to be present and then locate it\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "    )\n",
    "    \n",
    "    # Extract the addresses from the second cell of each row\n",
    "    addresses = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(2)\")\n",
    "    for address in addresses:\n",
    "        project_locations.append(address.text)\n",
    "\n",
    "    return project_locations\n",
    "\n",
    "# Example usage:\n",
    "driver = get_chrome_driver()\n",
    "url = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "project_addresses = extract_addresses_from_url(driver, url)\n",
    "for address in project_addresses:\n",
    "    print(address)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charles \"Chuck\" Minyard\n",
      "Mike Harrah, Caribou Industries\n",
      "Andrew Nelson, Red Oak Investments, LLC.\n",
      "Excel Property Management Services, Inc.\n",
      "Adan Madrid, ASI Development\n",
      "Kimberly Calica, AMG & Associates\n",
      "Alexis Gavorgian, AMG & Associates\n",
      "Vince Fregoso, studio 2 design + partners\n",
      "Ada Rose, YNG Architects\n",
      "City of Santa Ana\n",
      "Ryan Gahagan, Arrimus Capital\n",
      "City of Santa Ana\n",
      "Brandywine Acquisition Group, LLC.\n",
      "Grant Williams, FRH Realty, LLC. (Fairfield Residential)\n",
      "Michael Welles, Calvary Church\n",
      "Sean Rawson, Waterford Property Company\n",
      "City of Santa Ana\n",
      "City of Santa Ana\n",
      "City of Santa Ana\n",
      "Archangel Michael Coptic Orthodox\n",
      "Related Companies of California\n",
      "Pam Sapetto, Sapetto Real Estate Solutions\n",
      "HomeAid Mercy House\n",
      "Nick Chen\n",
      "City of Santa Ana\n",
      "Eric Higuchi, Grand Avenue, LLC.\n",
      "Quoc Phan, Haphan Group Inc.\n",
      "City of Santa Ana\n",
      "N/A\n",
      "Illumination Foundation\n",
      "Terri Dickerhoff, CGR Development\n",
      "Alexa Washburn, National Community Renaissance of California\n",
      "Legacy Partners\n",
      "Ki Ryu, Legado at the Met, LLC.\n",
      "Robert Bisno, Cabrillo Community Partners, LLC.\n",
      "Oliver Robinson, Centennial Properties\n",
      "Michael Gregg, Stream Realty\n",
      "City of Santa Ana\n",
      "Steve Jones, Olympia Capital Corporation\n",
      "Mike Harrah, Caribou Industries\n",
      "Rob Mitchell, Greenlaw Partners, LLC.\n",
      "Steven Oh, Related Companies of California\n",
      "Chase Russell, Russell Fischer Partnership\n",
      "Jeffrey M. Reese, C.J. Segerstrom & Sons\n",
      "City of Santa Ana\n",
      "Brian Hendricks, Magis Realty\n",
      "Justin McCusker, South Coast Plaza\n",
      "Red Hook Capital Partners, Enrique Diaz\n",
      "Greg Ocasek, Warmington Residential California, Inc.\n",
      "Habitat for Humanity Orange County\n",
      "Branden Wermers, Wermers Properties\n",
      "Cliff Jones with Griffin Residential\n",
      "Kyle Paine, Community Development Partners\n",
      "Brateil Aghasi, Executive Director WISEPlace\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def extract_applicants_from_url(driver, url):\n",
    "    \"\"\"\n",
    "    Navigates to a specified URL using the given driver and extracts applicants from a table.\n",
    "    \n",
    "    Parameters:\n",
    "    - driver: Selenium WebDriver\n",
    "    - url: Webpage URL\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of extracted applicants\n",
    "    \"\"\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    planner_leads = []\n",
    "    \n",
    "    # Wait for the table to be present and then locate it\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "    )\n",
    "    \n",
    "    # Extract the applicants from the third cell of each row\n",
    "    applicants = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(3)\")\n",
    "    for applicant in applicants:\n",
    "        planner_leads.append(applicant.text)\n",
    "\n",
    "    return planner_leads\n",
    "\n",
    "# Example usage:\n",
    "driver = get_chrome_driver()\n",
    "url = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "planners = extract_applicants_from_url(driver, url)\n",
    "for planner in planners:\n",
    "    print(planner)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primior, Inc.\n",
      "City of Santa Ana\n",
      "Los Altos XXI, LP GON-REY, LP.\n",
      "M&A Gabaee, LP.\n",
      "Euclid Hazard Capital LLC.\n",
      "Executive Car Leasing Co.\n",
      "Broomell Commercial Properties, LP.\n",
      "Nguyen, Long V.\n",
      "Nguyen, Kimloan J\n",
      "N/A\n",
      "RHW Holdings LLC.\n",
      "N/A\n",
      "The Provider Fund, LP.\n",
      "Mr. Dave Colton, The Colton Company\n",
      "Church Calvary of Santa Ana Inc.\n",
      "Park Center Santa Ana Associates LP.\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "Archangel Michael Coptic Orthodox\n",
      "Housing Authority of the City of Santa Ana\n",
      "QOZB IIII LLC.\n",
      "Housing Authority of the City of Santa Ana\n",
      "Garry Owners, LLC.\n",
      "N/A\n",
      "Grand Avenue Plaza, LLC.\n",
      "Haphan Group Inc.\n",
      "N/A\n",
      "LD Acquisition\n",
      "IHLLC Bewley, LLC.\n",
      "Orange County Community Housing Corporation\n",
      "Santa Ana United Methodist Church\n",
      "RAR2 651 Sunflower Owner LLC.\n",
      "Legado at the Met, LLC.\n",
      "First Credit Bank\n",
      "Mainplace Shoppingtown LLC.\n",
      "SRP/Stater Bros, LLC.\n",
      "N/A\n",
      "Mountainview Real Estate Investments LLC.\n",
      "One Broadway Plaza LLC.\n",
      "Greenlaw Partners, LLC.\n",
      "MCG Bristol West LLC.\n",
      "Russell Fischer Partnership, LP.\n",
      "C.J. Segerstrom & Sons\n",
      "N/A\n",
      "KB Home Coastal Inc.\n",
      "South Coast Plaza\n",
      "Vista Charter Schools, Colin Fletch\n",
      "Orange County Electrical Joint Apprenticeship Trust\n",
      "Habitat for Humanity of Orange County\n",
      "Santa Ana Apartments LLC.\n",
      "N/A\n",
      "Westminster & Fairview LLC.\n",
      "WISEPlace, a California nonprofit public benefit corporation\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def extract_property_owners_from_url(driver, url):\n",
    "    \"\"\"\n",
    "    Navigates to a specified URL using the given driver and extracts property owners from a table.\n",
    "    \n",
    "    Parameters:\n",
    "    - driver: Selenium WebDriver\n",
    "    - url: Webpage URL\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of extracted property owners\n",
    "    \"\"\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    property_owner = []\n",
    "    \n",
    "    # Wait for the table to be present and then locate it\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "    )\n",
    "    \n",
    "    # Extract the property owners from the fourth cell of each row\n",
    "    owners = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(4)\")\n",
    "    for owner in owners:\n",
    "        property_owner.append(owner.text)\n",
    "\n",
    "    return property_owner\n",
    "\n",
    "# Example usage:\n",
    "driver = get_chrome_driver()\n",
    "url = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "owners_list = extract_property_owners_from_url(driver, url)\n",
    "for owner_name in owners_list:\n",
    "    print(owner_name)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under Development Project Review\n",
      "Under Plan Check Review\n",
      "Under Plan Check Review\n",
      "Under Development Project Review\n",
      "Under Construction\n",
      "Under Development Project Review\n",
      "Completed\n",
      "Under Development Project Review\n",
      "Under Plan Check Review\n",
      "Under Review\n",
      "Under Construction\n",
      "Completed\n",
      "Under Plan Check Review\n",
      "Project Denied\n",
      "Under Public Hearings\n",
      "Under Plan Check Review\n",
      "Completed\n",
      "Completed\n",
      "Completed\n",
      "Under Public Hearing\n",
      "Under Construction\n",
      "Under Construction\n",
      "Under Construction\n",
      "Under Plan Check Review\n",
      "In Process\n",
      "Under Development Project Review\n",
      "Under Plan Check Review\n",
      "In Process\n",
      "Completed\n",
      "Under Review\n",
      "Under Development Project Review\n",
      "Completed\n",
      "Completed\n",
      "Under Plan Check Review\n",
      "Under Plan Check Review\n",
      "Under Plan Check Review\n",
      "Under Development Project Review\n",
      "Completed\n",
      "Under Plan Check Review\n",
      "Under Plan Check Review\n",
      "Under Review\n",
      "Under Development Project Review\n",
      "Under Construction\n",
      "Under Development Project Review\n",
      "Under Development Project Review\n",
      "Under Plan Check Review\n",
      "Under Development Project Review\n",
      "Under Development Project Review\n",
      "Under Development Project Review\n",
      "Under Development Project Review\n",
      "Under Construction\n",
      "Under Development Project Review\n",
      "Under Construction\n",
      "Under Construction\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def extract_project_status_from_url(driver, url):\n",
    "    \"\"\"\n",
    "    Navigates to a specified URL using the given driver and extracts project statuses from a table.\n",
    "    \n",
    "    Parameters:\n",
    "    - driver: Selenium WebDriver\n",
    "    - url: Webpage URL\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of extracted project statuses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    project_status = []\n",
    "    \n",
    "    # Wait for the table to be present and then locate it\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "    )\n",
    "    \n",
    "    # Extract the project statuses from the fifth cell of each row\n",
    "    status = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(5)\")\n",
    "    for stats in status:\n",
    "        project_status.append(stats.text)\n",
    "\n",
    "    return project_status\n",
    "\n",
    "# Example usage:\n",
    "driver = get_chrome_driver()\n",
    "url = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "status_list = extract_project_status_from_url(driver, url)\n",
    "for status_name in status_list:\n",
    "    print(status_name)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Project Names                         Addresses  \\\n",
      "0        1st and Harbor Mix-Use Development  101 N. Harbor Boulevard (Ward 5)   \n",
      "1      3rd and Broadway Mix-Use Development        201 W. 3rd Street (Ward 5)   \n",
      "2   4th and Mortimer Mixed-Used Development        409 E. 4th Street (Ward 6)   \n",
      "3      5th and Harbor Mixed-Use Development       419 N. Harbor Blvd (Ward 5)   \n",
      "4  7-Eleven Service Station (Euclid Street)     813 N. Euclid Street (Ward 1)   \n",
      "\n",
      "                                 Applicants                 Property Owners  \\\n",
      "0                   Charles \"Chuck\" Minyard                   Primior, Inc.   \n",
      "1           Mike Harrah, Caribou Industries               City of Santa Ana   \n",
      "2  Andrew Nelson, Red Oak Investments, LLC.  Los Altos XXI, LP GON-REY, LP.   \n",
      "3  Excel Property Management Services, Inc.                 M&A Gabaee, LP.   \n",
      "4              Adan Madrid, ASI Development      Euclid Hazard Capital LLC.   \n",
      "\n",
      "                     Project Status  \n",
      "0  Under Development Project Review  \n",
      "1           Under Plan Check Review  \n",
      "2           Under Plan Check Review  \n",
      "3  Under Development Project Review  \n",
      "4                Under Construction  \n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "def extract_table_data_from_url(driver, url):\n",
    "    \"\"\"\n",
    "    Navigates to a specified URL using the given driver and extracts data from the table.\n",
    "    \n",
    "    Parameters:\n",
    "    - driver: Selenium WebDriver\n",
    "    - url: Webpage URL\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A pandas DataFrame containing the extracted table data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for the table to be present and then locate it\n",
    "    main = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "    )\n",
    "    \n",
    "    # Define a helper function to extract column data\n",
    "    def extract_column_data(column_index):\n",
    "        return [cell.text for cell in main.find_elements(By.CSS_SELECTOR, f\"#projectList tr td:nth-of-type({column_index})\")]\n",
    "    \n",
    "    # Extract data from the table\n",
    "    project_names = extract_column_data(1)\n",
    "    addresses = extract_column_data(2)\n",
    "    applicants = extract_column_data(3)\n",
    "    property_owners = extract_column_data(4)\n",
    "    project_statuses = extract_column_data(5)\n",
    "    \n",
    "    # Collate the data into a pandas DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Project Names\": project_names,\n",
    "        \"Addresses\": addresses,\n",
    "        \"Applicants\": applicants,\n",
    "        \"Property Owners\": property_owners,\n",
    "        \"Project Status\": project_statuses\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "driver = get_chrome_driver()\n",
    "url = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "data_df = extract_table_data_from_url(driver, url)\n",
    "print(data_df.head())  # To display the first few rows of the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that data is extracted, we can add more information through the project links on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major planning projects and monthly development reports - City of Santa Ana\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\regionintelligenceai\\notebooks\\data gathering\\01_SantaAna_Scraper.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=208'>209</a>\u001b[0m scraper\u001b[39m.\u001b[39mconnect(URL)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=209'>210</a>\u001b[0m scraper\u001b[39m.\u001b[39mscrape_base_directory()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=210'>211</a>\u001b[0m scraper\u001b[39m.\u001b[39;49mscrape_detailed_info()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=211'>212</a>\u001b[0m df \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39mcreate_dataframe()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=212'>213</a>\u001b[0m scraper\u001b[39m.\u001b[39mclean_data()\n",
      "\u001b[1;32mc:\\Projects\\regionintelligenceai\\notebooks\\data gathering\\01_SantaAna_Scraper.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m link \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mLINK_TEXT, link)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39marguments[0].scrollIntoView();\u001b[39m\u001b[39m\"\u001b[39m, link)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m link\u001b[39m.\u001b[39;49mclick()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scrape_project_details()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/notebooks/data%20gathering/01_SantaAna_Scraper.ipynb#X36sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdriver\u001b[39m.\u001b[39mback()\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:93\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclick\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(Command\u001b[39m.\u001b[39;49mCLICK_ELEMENT)\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:394\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[0;32m    393\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[1;32m--> 394\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m    340\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m--> 342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:297\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    295\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[0;32m    296\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:318\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    315\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 318\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    319\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[0;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\urllib3\\_request_methods.py:118\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    111\u001b[0m         method,\n\u001b[0;32m    112\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw,\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[0;32m    119\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[0;32m    120\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\urllib3\\_request_methods.py:217\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    213\u001b[0m     extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m, content_type)\n\u001b[0;32m    215\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Projects\\regionintelligenceai\\.venv\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "class SantaAnaScraper:\n",
    "    def __init__(self, driver):\n",
    "        self.driver = driver\n",
    "        self.listing_names = []\n",
    "        self.project_locations = []\n",
    "        self.planner_leads = []\n",
    "        self.property_owner = []\n",
    "        self.project_status = []\n",
    "        self.project_descriptions = []\n",
    "        self.contact_information = []\n",
    "        self.last_project_update = []\n",
    "        self.all_images_urls = []\n",
    "        self.df = None\n",
    "\n",
    "    def connect(self, url):\n",
    "        self.driver.get(url)\n",
    "        print(self.driver.title)\n",
    "\n",
    "    def scrape_base_directory(self):\n",
    "        try:\n",
    "            main = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"#projectList\"))\n",
    "            )\n",
    "            self._scrape_titles(main)\n",
    "            self._scrape_addresses(main)\n",
    "            self._scrape_applicants(main)\n",
    "            self._scrape_owners(main)\n",
    "            self._scrape_status(main)\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    def _scrape_titles(self, main):\n",
    "        titles = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:first-of-type\")\n",
    "        for title in titles:\n",
    "            self.listing_names.append(title.text)\n",
    "\n",
    "    def _scrape_addresses(self, main):\n",
    "        addresses = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(2)\")\n",
    "        for address in addresses:\n",
    "            self.project_locations.append(address.text)\n",
    "\n",
    "    def _scrape_applicants(self, main):\n",
    "        applicants = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(3)\")\n",
    "        for applicant in applicants:\n",
    "            self.planner_leads.append(applicant.text)\n",
    "\n",
    "    def _scrape_owners(self, main):\n",
    "        owners = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(4)\")\n",
    "        for owner in owners:\n",
    "            self.property_owner.append(owner.text)\n",
    "\n",
    "    def _scrape_status(self, main):\n",
    "        status = main.find_elements(By.CSS_SELECTOR, \"#projectList tr td:nth-of-type(5)\")\n",
    "        for stats in status:\n",
    "            self.project_status.append(stats.text)\n",
    "\n",
    "    def scrape_detailed_info(self):\n",
    "        for link in self.listing_names:\n",
    "            link = link.strip()\n",
    "            link = self.driver.find_element(By.LINK_TEXT, link)\n",
    "            self.driver.execute_script(\"arguments[0].scrollIntoView();\", link)\n",
    "            link.click()\n",
    "            self._scrape_project_details()\n",
    "            self.driver.back()\n",
    "\n",
    "    def _scrape_project_details(self):\n",
    "        try:\n",
    "            element = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, \".so-widget-sow-editor.so-widget-sow-editor-base\")\n",
    "                )\n",
    "            )\n",
    "            self._scrape_project_description(element)\n",
    "            self._scrape_contact_info(element)\n",
    "            self._scrape_last_updated(element)\n",
    "            self._scrape_image_urls()\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "    def _scrape_project_description(self, element):\n",
    "        try:\n",
    "            description = element.find_element(By.CSS_SELECTOR, \"ul:first-of-type li:first-child\")\n",
    "            self.project_descriptions.append(description.text)\n",
    "        except:\n",
    "            self.project_descriptions.append(\"NA\")\n",
    "\n",
    "    def _scrape_contact_info(self, element):\n",
    "        try:\n",
    "            contact_info = element.find_element(By.CSS_SELECTOR, \"p\")\n",
    "            self.contact_information.append(contact_info.text)\n",
    "        except:\n",
    "            self.contact_information.append(\"NA\")\n",
    "\n",
    "    def _scrape_last_updated(self, element):\n",
    "        try:\n",
    "            last_updated = element.find_element(By.CSS_SELECTOR, \"p > em\")\n",
    "            self.last_project_update.append(last_updated.text)\n",
    "        except:\n",
    "            self.last_project_update.append(\"NA\")\n",
    "\n",
    "    def _scrape_image_urls(self):\n",
    "        image_url = None\n",
    "        # Locate div elements\n",
    "        div_elements = self.driver.find_elements(\n",
    "            By.CSS_SELECTOR, \"div.siteorigin-widget-tinymce.textwidget\"\n",
    "        )\n",
    "\n",
    "        for div in div_elements:\n",
    "            image_urls = []\n",
    "            try:\n",
    "                # Locate every img tag that is inside a p element following an a tag within the current div\n",
    "                images_in_div = div.find_elements(By.CSS_SELECTOR, \"p a img\")\n",
    "\n",
    "                # Extract the src attribute of each img tag found\n",
    "                for img in images_in_div:\n",
    "                    image_url = img.get_attribute(\"src\")\n",
    "                    if image_url:\n",
    "                        image_urls.append(image_url)\n",
    "                    else:\n",
    "                        image_urls.append(\"NA\")\n",
    "            except Exception as e:\n",
    "                print(\"Exception occurred: \", e)\n",
    "                image_urls.append(\"NA\")\n",
    "\n",
    "            self.all_images_urls.append(image_urls)\n",
    "    \n",
    "    def clean_data(self):\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"DataFrame not yet created. Call create_dataframe first.\")\n",
    "        else:\n",
    "        # Split the Planner/Manager column into name and the rest\n",
    "            self.df[[\"Name\", \"Rest\"]] = self.df[\"Planner/Manager\"].str.split(\n",
    "                \"Phone:\", expand=True\n",
    "            )\n",
    "\n",
    "            # Now split the rest into phone and email using re.split\n",
    "            # Handle potential non-string (NaN) values in the 'Rest' column\n",
    "            self.df[\"Phone\"], self.df[\"Email\"] = zip(\n",
    "                *self.df[\"Rest\"].apply(\n",
    "                    lambda x: re.split(\"E-mail:|Email:\", x)\n",
    "                    if isinstance(x, str)\n",
    "                    else (np.nan, np.nan)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Remove unnecessary strings\n",
    "            self.df[\"Name\"] = (\n",
    "                self.df[\"Name\"].str.replace(\"Project Manager:\", \"\").str.strip()\n",
    "            )\n",
    "            self.df[\"Phone\"] = self.df[\"Phone\"].str.strip()\n",
    "            self.df[\"Email\"] = self.df[\"Email\"].str.strip()\n",
    "\n",
    "        # Clean Emails that did not parse correctly. Using helper method. \n",
    "        def clean_email(value):  # Helper method for cleaning emails\n",
    "            if isinstance(value, str):  # Check if value is a string\n",
    "                potential_email = value.split('\\n')[0]\n",
    "                if \"@\" in potential_email and \".\" in potential_email:\n",
    "                    return potential_email\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None  # Return None if value is not a string (like NaN)\n",
    "            \n",
    "        self.df[\"Email\"] = self.df[\"Email\"].apply(clean_email)\n",
    "\n",
    "        # Drop the 'Rest' and 'Planner/Manager' columns as they are not needed anymore\n",
    "        self.df.drop([\"Rest\", \"Planner/Manager\"], axis=1, inplace=True)\n",
    "\n",
    "            # Group by 'Name', then fill missing 'Phone' and 'Email' with the mode value in each group\n",
    "        self.df[\"Phone\"] = self.df.groupby(\"Name\")[\"Phone\"].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else \"Unknown\")\n",
    "            )\n",
    "        self.df[\"Email\"] = self.df.groupby(\"Name\")[\"Email\"].transform(\n",
    "                lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else \"Unknown\")\n",
    "            )\n",
    "\n",
    "    def save_to_s3(self, file_name):\n",
    "        self.df.to_excel(file_name, header=True)\n",
    "\n",
    "    def create_dataframe(self):\n",
    "        self.df = pd.DataFrame(\n",
    "            {\n",
    "                \"Listing Names\": self.listing_names,\n",
    "                \"Project Locations\": self.project_locations,\n",
    "                \"Planner Leads\": self.planner_leads,\n",
    "                \"Owner\": self.property_owner,\n",
    "                \"Image Url\": self.all_images_urls,\n",
    "                \"Project Status\": self.project_status,\n",
    "                \"Description\": self.project_descriptions,\n",
    "                \"Planner/Manager\": self.contact_information,\n",
    "                \"Last Project Update\": self.last_project_update,\n",
    "            }\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "# Usage example\n",
    "driver = get_chrome_driver()\n",
    "scraper = SantaAnaScraper(driver)\n",
    "URL = \"https://www.santa-ana.org/major-planning-projects-and-monthly-development-project-reports/\"\n",
    "scraper.connect(URL)\n",
    "scraper.scrape_base_directory()\n",
    "scraper.scrape_detailed_info()\n",
    "df = scraper.create_dataframe()\n",
    "scraper.clean_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APezeshkpour@santa-ana.org\\n\\nUpdated: August 4, 2020'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Email'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Email\n",
      "0             test1@email.com\n",
      "1             test2@email.com\n",
      "2  APezeshkpour@santa-ana.org\n",
      "3             test4@email.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for demonstration\n",
    "data = {\n",
    "    'Email': ['test1@email.com', 'test2@email.com', 'APezeshkpour@santa-ana.org\\n\\nUpdated: August 4, 2020', 'test4@email.com']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to clean up the email\n",
    "def clean_email(value):\n",
    "    # Splitting by the newline character and considering only the first part\n",
    "    potential_email = value.split('\\n')[0]\n",
    "    \n",
    "    # Basic email validation: Checking if there's an \"@\" and a \".\"\n",
    "    # You can use more sophisticated validation if necessary\n",
    "    if \"@\" in potential_email and \".\" in potential_email:\n",
    "        return potential_email\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['Email'] = df['Email'].apply(clean_email)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_names[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
