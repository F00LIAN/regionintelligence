{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\regionintelligenceai\\dev_llm\\modules\\q_and_a_generator\\q_a_notebooks\\05_generate_dataset.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpaths\u001b[39;00m \u001b[39mimport\u001b[39;00m JSON_DATA_DIR\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m get_console_logger\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/')\n",
    "\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import hashlib\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.cleaners.core import clean, replace_unicode_quotes, clean_non_ascii_chars\n",
    "from unstructured.staging.huggingface import chunk_by_attention_window\n",
    "from unstructured.staging.huggingface import stage_for_transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.paths import JSON_DATA_DIR\n",
    "from src.logger import get_console_logger\n",
    "\n",
    "\n",
    "\n",
    "QDRANT_API_KEY = os.environ.get('QDRANT_API_KEY')\n",
    "QDRANT_API_URL = os.environ.get('QDRANT_API_URL')\n",
    "\n",
    "CALIFORNIA_JSON_FILE = JSON_DATA_DIR / 'california_building_codes_json' / 'california_20231015.json'\n",
    "QDRANT_COLLECTION_NAME = 'california_building_codes'\n",
    "QDRANT_VECTOR_SIZE = 384\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_qdrant_client' from 'src.vector_db_api' (c:\\Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator\\src\\vector_db_api.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\regionintelligenceai\\dev_llm\\modules\\q_and_a_generator\\q_a_notebooks\\05_generate_dataset.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# init qdrant client and collection where we store the news\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvector_db_api\u001b[39;00m \u001b[39mimport\u001b[39;00m get_qdrant_client, init_collection\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m qdrant_client \u001b[39m=\u001b[39m get_qdrant_client()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m qdrant_client \u001b[39m=\u001b[39m init_collection(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     qdrant_client\u001b[39m=\u001b[39mqdrant_client,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     collection_name\u001b[39m=\u001b[39mQDRANT_COLLECTION_NAME,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     vector_size\u001b[39m=\u001b[39mQDRANT_VECTOR_SIZE,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator/q_a_notebooks/05_generate_dataset.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_qdrant_client' from 'src.vector_db_api' (c:\\Projects/regionintelligenceai/dev_llm/modules/q_and_a_generator\\src\\vector_db_api.py)"
     ]
    }
   ],
   "source": [
    "# init logger\n",
    "logger = get_console_logger()\n",
    "\n",
    "# tokenizer and LLM we use to embed the document text\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# init qdrant client and collection where we store the news\n",
    "from src.vector_db_api import get_qdrant_client, init_collection\n",
    "qdrant_client = get_qdrant_client()\n",
    "qdrant_client = init_collection(\n",
    "    qdrant_client=qdrant_client,\n",
    "    collection_name=QDRANT_COLLECTION_NAME,\n",
    "    vector_size=QDRANT_VECTOR_SIZE,\n",
    ")\n",
    "\n",
    "class Document(BaseModel):\n",
    "    id: str\n",
    "    group_key: Optional[str] = None\n",
    "    metadata: Optional[dict] = {}\n",
    "    text: Optional[list] = []\n",
    "    chunks: Optional[list] = []\n",
    "    embeddings: Optional[list] = []\n",
    "\n",
    "def parse_document(chapter_data: Dict) -> Document:\n",
    "    try:\n",
    "        document_id = hashlib.md5(str(chapter_data).encode()).hexdigest()\n",
    "        document = Document(id=document_id)\n",
    "        texts = []\n",
    "\n",
    "        for section in chapter_data['sections']:\n",
    "            texts.append(section['title'])\n",
    "            texts.append(section['content'])\n",
    "            for subsection in section['subsections']:\n",
    "                texts.append(subsection['title'])\n",
    "                texts.append(subsection['content'])\n",
    "\n",
    "        joined_text = \" \".join(texts)\n",
    "        document.text = [joined_text]\n",
    "        document.metadata['chapter'] = chapter_data['chapter']\n",
    "        \n",
    "        return document\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error parsing document: {e}\")\n",
    "        return None\n",
    "    \n",
    "def chunk(document: Document) -> Document:\n",
    "    try:\n",
    "        chunks = []\n",
    "        for text in document.text:\n",
    "            chunks += chunk_by_attention_window(\n",
    "                text, tokenizer, max_input_size=QDRANT_VECTOR_SIZE)\n",
    "        \n",
    "        document.chunks = chunks\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error chunking document: {e}\")\n",
    "        return None\n",
    "\n",
    "def embedding(document: Document) -> Document:\n",
    "    try:\n",
    "        for chunk in document.text:\n",
    "            inputs = tokenizer(chunk,\n",
    "                               padding=True,\n",
    "                               truncation=True,\n",
    "                               return_tensors=\"pt\",\n",
    "                               max_length=QDRANT_VECTOR_SIZE)\n",
    "\n",
    "            result = model(**inputs)\n",
    "            embeddings = result.last_hidden_state[:, 0, :].cpu().detach().numpy()\n",
    "            lst = embeddings.flatten().tolist()\n",
    "            document.embeddings.append(lst)\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while embedding document: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_payloads(doc: Document) -> List:\n",
    "    try:\n",
    "        payloads = []\n",
    "        for chunk in doc.chunks:\n",
    "            payload = doc.metadata\n",
    "            payload.update({\"text\": chunk})\n",
    "            payloads.append(payload)\n",
    "        return payloads\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while building payloads: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def push_document_to_qdrant(doc: Document) -> None:\n",
    "    try:\n",
    "        from qdrant_client.models import PointStruct\n",
    "\n",
    "        _payloads = build_payloads(doc)\n",
    "\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=QDRANT_COLLECTION_NAME,\n",
    "            points=[\n",
    "                PointStruct(\n",
    "                    id=idx,\n",
    "                    vector=vector,\n",
    "                    payload=_payload\n",
    "                )\n",
    "                for idx, (vector, _payload) in enumerate(zip(doc.embeddings, _payloads))\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while pushing document to Qdrant: {e}\")\n",
    "\n",
    "\n",
    "def process_one_building_code(_data: Dict) -> None:\n",
    "    \"\"\"Process a single building code.\"\"\"\n",
    "    try:\n",
    "        doc = parse_document(_data)\n",
    "        if doc is None:\n",
    "            return None\n",
    "        doc = chunk(doc)\n",
    "        if doc is None:\n",
    "            return None\n",
    "        doc = embedding(doc)\n",
    "        if doc is None:\n",
    "            return None\n",
    "        push_document_to_qdrant(doc)\n",
    "\n",
    "        return doc\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while processing building code: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_one_document(_data: Dict) -> None:\n",
    "    \"\"\"\"\"\"\n",
    "    try:\n",
    "        doc = parse_document(_data)\n",
    "        if doc:\n",
    "            doc = chunk(doc)\n",
    "            doc = embedding(doc)\n",
    "            push_document_to_qdrant(doc)\n",
    "        return doc\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while processing one building code document: {e}\")\n",
    "        return None\n",
    "    \n",
    "def embed_building_codes_into_qdrant(building_codes_data: List[Dict], n_processes: int = 1) -> None:\n",
    "    \"\"\"\"\"\"\n",
    "    results = []\n",
    "    try:\n",
    "        if n_processes == 1:\n",
    "            # sequential\n",
    "            for _data in tqdm(building_codes_data):\n",
    "                result = process_one_document(_data)\n",
    "                results.append(result)\n",
    "        else:\n",
    "            # parallel\n",
    "            import multiprocessing\n",
    "\n",
    "            # Create a multiprocessing Pool\n",
    "            with multiprocessing.Pool(processes=n_processes) as pool:\n",
    "                # Use tqdm to create a progress bar\n",
    "                results = list(tqdm(pool.imap(process_one_document, building_codes_data),\n",
    "                                    total=len(building_codes_data),\n",
    "                                    desc=\"Processing\",\n",
    "                                    unit=\"building_code\"))\n",
    "\n",
    "        breakpoint()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while embedding building codes into Qdrant: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\"\"\"\n",
    "    import json\n",
    "    with open(CALIFORNIA_JSON_FILE, 'r') as json_file:\n",
    "        building_codes_data = json.load(json_file)\n",
    "\n",
    "    embed_building_codes_into_qdrant(\n",
    "        building_codes_data,\n",
    "        n_processes=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
